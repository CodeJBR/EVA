{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOZ0qcNs7pfKXh5cEMPyNiv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeJBR/EVA/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "550zcuVB7PQr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "1. What are Channels and Kernels (according to EVA)?\n",
        "    * **Channels** are the containers which hold one contextual information called **features**. Features are the basic building blocks or alphabets which make up the whole of a dataset - in this case an image since EVA is focussed on Vision. This means if we were to break down an image into multiple components, it would be these alphabets that would be the unit of our breakage and all such collection of one type of alphabet is our channel. Maybe this can be best illustrated with examples from different perspective :-\n",
        "        * In an image say print newspaper page, these are the following ways I can get a feature and a feature map - channel\n",
        "            * If I consider the English alphabets as features, then all positioning of say letter m on that page is a channel for us\n",
        "            * If I consider the colours CMYK as features, then disintegrating the image into only color Yellow on that page becomes a channel for us. This means if we bring back all the channels together we will get our full image back much like a overhead projector which uses transparent plastic sheet to show images and can be change at runtime by overlaying another plastic film to show a completely different visualization\n",
        "        * Another example would be if we think in 3D the construction of a house\n",
        "            * If we consider walls, pillars and roof as one feature, then their positioning in 3D that means the 3D positioning of all walls in the model of the house becomes a channel. If we bring combine the 3D positioning of walls, pillars and roofs, we get the full house\n",
        "            * Another way to look at it would be to break down into much basic components like iron rods, cement, wood, stones and bricks. The 3D positioning of all bricks becomes a channel where brick is the feature. The granularity is something we can decide but once decided the dataset is broken based on that granularity and then we get a channel or feature map for the same\n",
        "    * **Kernels** are the feature extractors which gives us the feature map or channels. Now that we have defined channel, question is what gives us this channel or polarised view of our dataset. Say for example, I had a lens using which I could only see the :-\n",
        "        * **Y** color in CMYK of a newspaper page\n",
        "        * Positioning of all **M** alphabets on the page\n",
        "        * Only able to see the **walls** of a house in 3D\n",
        "        * Only able to see the **bricks** layout of a house in 3D\n",
        "    * In that case this lens available to me is the Kernel. In case of EVA since we concentrate on images we think of a kernel as 3x3 matrix of random numbers which extracts a particular feature for me to get me a feature map or channel at a particular level. For example if we use a 3x3 kernel to convolve over an image then it will look like this :-\n",
        "\n",
        "        * If an image is 3x3 , by convolution we mean the dot product of this 3x3 matrix image to the 3x3 kernel matrix so in this case we get a single number representing the entire 3x3 image. If you notice this number has seen the full image and extracts an aspect or feature of the image using the kernel and encodes this data in the dot product. This is also called the global receptive field - when a convolution has seen the full image \n",
        "        * If the image were to be 5x5, then it would require a 9 such convolutions of 3x3 kernel over this 5x5  image to produce a 3x3 matrix (a local receptive field) and would again have to be convolved, by a higher kernel specialized for that layer, to get one final global receptive field ![convolution](https://miro.medium.com/max/1052/1*GcI7G-JLAQiEoCON7xFbhg.gif)\n",
        "        \n",
        "        So at each convolution layer the kernel remains fixed and we get a collection of local receptive fields commonly known as channels. With convolution at each layer with these specialised kernels we get to see the full image or global receptive field so if we start with very low level features like edges then proceed to gradients and then to parts of objects and finally objects, the full picture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1soejs6x6WgM",
        "colab_type": "text"
      },
      "source": [
        "2. Why should we (nearly) always use 3x3 kernels?\n",
        "    *  We should always use 3x3 kernels because :-\n",
        "        1. A 3x3 kernel provides a definitive answer to a question like what edges are present say suppose we are convolving on an image with a 2x2 kernel, with an even number we would not be sure of how distinct an edge is but with an odd number we would know where it ends definitively\n",
        "        2. Every n x m matrix can be reached with a 3x3 matrix like 5x5, 7x7, 9x9 and so on.\n",
        "        3. 2x2 is a subset of 3x3 matrix with last row and column padded with 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWItWAjc9TvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab8663ba-e08e-480e-d2d9-dfeec774bce0"
      },
      "source": [
        "print(\"How many times to we need to perform 3x3 convolutions operations to reach close to 1x1 from 199x199 (type each layer output like 199x199 > 197x197...\",end=\"\\n\")\n",
        "\n",
        "print(\"We need to perform the convolution operation 99 times\",end=\"\\n\")\n",
        "print(\"working is provided below\")\n",
        "i=199\n",
        "c=1\n",
        "print(\"Image Size\",\"|\",\"Local receptive field\",\"|\",\"Iteration\",\"|\",\"result\")\n",
        "while i > 2:\n",
        "  print(i ,\"x\",i,\" | \",\"3x3\",\" | \",c,\" | \",\">\",i-2,\"x\",i-2)\n",
        "  i=i-2\n",
        "  c=c+1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How many times to we need to perform 3x3 convolutions operations to reach close to 1x1 from 199x199 (type each layer output like 199x199 > 197x197...\n",
            "We need to perform the convolution operation 99 times\n",
            "working is provided below\n",
            "Image Size | Local receptive field | Iteration | result\n",
            "199 x 199  |  3x3  |  1  |  > 197 x 197\n",
            "197 x 197  |  3x3  |  2  |  > 195 x 195\n",
            "195 x 195  |  3x3  |  3  |  > 193 x 193\n",
            "193 x 193  |  3x3  |  4  |  > 191 x 191\n",
            "191 x 191  |  3x3  |  5  |  > 189 x 189\n",
            "189 x 189  |  3x3  |  6  |  > 187 x 187\n",
            "187 x 187  |  3x3  |  7  |  > 185 x 185\n",
            "185 x 185  |  3x3  |  8  |  > 183 x 183\n",
            "183 x 183  |  3x3  |  9  |  > 181 x 181\n",
            "181 x 181  |  3x3  |  10  |  > 179 x 179\n",
            "179 x 179  |  3x3  |  11  |  > 177 x 177\n",
            "177 x 177  |  3x3  |  12  |  > 175 x 175\n",
            "175 x 175  |  3x3  |  13  |  > 173 x 173\n",
            "173 x 173  |  3x3  |  14  |  > 171 x 171\n",
            "171 x 171  |  3x3  |  15  |  > 169 x 169\n",
            "169 x 169  |  3x3  |  16  |  > 167 x 167\n",
            "167 x 167  |  3x3  |  17  |  > 165 x 165\n",
            "165 x 165  |  3x3  |  18  |  > 163 x 163\n",
            "163 x 163  |  3x3  |  19  |  > 161 x 161\n",
            "161 x 161  |  3x3  |  20  |  > 159 x 159\n",
            "159 x 159  |  3x3  |  21  |  > 157 x 157\n",
            "157 x 157  |  3x3  |  22  |  > 155 x 155\n",
            "155 x 155  |  3x3  |  23  |  > 153 x 153\n",
            "153 x 153  |  3x3  |  24  |  > 151 x 151\n",
            "151 x 151  |  3x3  |  25  |  > 149 x 149\n",
            "149 x 149  |  3x3  |  26  |  > 147 x 147\n",
            "147 x 147  |  3x3  |  27  |  > 145 x 145\n",
            "145 x 145  |  3x3  |  28  |  > 143 x 143\n",
            "143 x 143  |  3x3  |  29  |  > 141 x 141\n",
            "141 x 141  |  3x3  |  30  |  > 139 x 139\n",
            "139 x 139  |  3x3  |  31  |  > 137 x 137\n",
            "137 x 137  |  3x3  |  32  |  > 135 x 135\n",
            "135 x 135  |  3x3  |  33  |  > 133 x 133\n",
            "133 x 133  |  3x3  |  34  |  > 131 x 131\n",
            "131 x 131  |  3x3  |  35  |  > 129 x 129\n",
            "129 x 129  |  3x3  |  36  |  > 127 x 127\n",
            "127 x 127  |  3x3  |  37  |  > 125 x 125\n",
            "125 x 125  |  3x3  |  38  |  > 123 x 123\n",
            "123 x 123  |  3x3  |  39  |  > 121 x 121\n",
            "121 x 121  |  3x3  |  40  |  > 119 x 119\n",
            "119 x 119  |  3x3  |  41  |  > 117 x 117\n",
            "117 x 117  |  3x3  |  42  |  > 115 x 115\n",
            "115 x 115  |  3x3  |  43  |  > 113 x 113\n",
            "113 x 113  |  3x3  |  44  |  > 111 x 111\n",
            "111 x 111  |  3x3  |  45  |  > 109 x 109\n",
            "109 x 109  |  3x3  |  46  |  > 107 x 107\n",
            "107 x 107  |  3x3  |  47  |  > 105 x 105\n",
            "105 x 105  |  3x3  |  48  |  > 103 x 103\n",
            "103 x 103  |  3x3  |  49  |  > 101 x 101\n",
            "101 x 101  |  3x3  |  50  |  > 99 x 99\n",
            "99 x 99  |  3x3  |  51  |  > 97 x 97\n",
            "97 x 97  |  3x3  |  52  |  > 95 x 95\n",
            "95 x 95  |  3x3  |  53  |  > 93 x 93\n",
            "93 x 93  |  3x3  |  54  |  > 91 x 91\n",
            "91 x 91  |  3x3  |  55  |  > 89 x 89\n",
            "89 x 89  |  3x3  |  56  |  > 87 x 87\n",
            "87 x 87  |  3x3  |  57  |  > 85 x 85\n",
            "85 x 85  |  3x3  |  58  |  > 83 x 83\n",
            "83 x 83  |  3x3  |  59  |  > 81 x 81\n",
            "81 x 81  |  3x3  |  60  |  > 79 x 79\n",
            "79 x 79  |  3x3  |  61  |  > 77 x 77\n",
            "77 x 77  |  3x3  |  62  |  > 75 x 75\n",
            "75 x 75  |  3x3  |  63  |  > 73 x 73\n",
            "73 x 73  |  3x3  |  64  |  > 71 x 71\n",
            "71 x 71  |  3x3  |  65  |  > 69 x 69\n",
            "69 x 69  |  3x3  |  66  |  > 67 x 67\n",
            "67 x 67  |  3x3  |  67  |  > 65 x 65\n",
            "65 x 65  |  3x3  |  68  |  > 63 x 63\n",
            "63 x 63  |  3x3  |  69  |  > 61 x 61\n",
            "61 x 61  |  3x3  |  70  |  > 59 x 59\n",
            "59 x 59  |  3x3  |  71  |  > 57 x 57\n",
            "57 x 57  |  3x3  |  72  |  > 55 x 55\n",
            "55 x 55  |  3x3  |  73  |  > 53 x 53\n",
            "53 x 53  |  3x3  |  74  |  > 51 x 51\n",
            "51 x 51  |  3x3  |  75  |  > 49 x 49\n",
            "49 x 49  |  3x3  |  76  |  > 47 x 47\n",
            "47 x 47  |  3x3  |  77  |  > 45 x 45\n",
            "45 x 45  |  3x3  |  78  |  > 43 x 43\n",
            "43 x 43  |  3x3  |  79  |  > 41 x 41\n",
            "41 x 41  |  3x3  |  80  |  > 39 x 39\n",
            "39 x 39  |  3x3  |  81  |  > 37 x 37\n",
            "37 x 37  |  3x3  |  82  |  > 35 x 35\n",
            "35 x 35  |  3x3  |  83  |  > 33 x 33\n",
            "33 x 33  |  3x3  |  84  |  > 31 x 31\n",
            "31 x 31  |  3x3  |  85  |  > 29 x 29\n",
            "29 x 29  |  3x3  |  86  |  > 27 x 27\n",
            "27 x 27  |  3x3  |  87  |  > 25 x 25\n",
            "25 x 25  |  3x3  |  88  |  > 23 x 23\n",
            "23 x 23  |  3x3  |  89  |  > 21 x 21\n",
            "21 x 21  |  3x3  |  90  |  > 19 x 19\n",
            "19 x 19  |  3x3  |  91  |  > 17 x 17\n",
            "17 x 17  |  3x3  |  92  |  > 15 x 15\n",
            "15 x 15  |  3x3  |  93  |  > 13 x 13\n",
            "13 x 13  |  3x3  |  94  |  > 11 x 11\n",
            "11 x 11  |  3x3  |  95  |  > 9 x 9\n",
            "9 x 9  |  3x3  |  96  |  > 7 x 7\n",
            "7 x 7  |  3x3  |  97  |  > 5 x 5\n",
            "5 x 5  |  3x3  |  98  |  > 3 x 3\n",
            "3 x 3  |  3x3  |  99  |  > 1 x 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JehF9uP7Ilr",
        "colab_type": "text"
      },
      "source": [
        "4. How are kernels initialized? \n",
        "    * Kernel are initialised randomly but it should be appropriate to extracting the channel or feature map we want. Earlier actually people used to do it manually but now machines generate these kernels which are accurate and produce better results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7DtwVyt7RBJ",
        "colab_type": "text"
      },
      "source": [
        "5. What happens during the training of a DNN?\n",
        "* During the training of Deep Neural Network, the DNN figures out the best kernels that can be used to convolve a dataset. Among a host of candidate kernels, it chooses only those which are best suited to describe that dataset and would produce accurate results for feature extraction of a particular types. The same kernels cannot be used for other datasets or images and DNN has to be trained again to deal with those datasets. Although the kernel size remains the same at each layer, the kind of kernel change because the kernel at nth layer is best suited for seeing the full image (extarcting the channel defined) at that level over other , maybe closely competent, kernels."
      ]
    }
  ]
}